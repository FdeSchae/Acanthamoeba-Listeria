{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Chemotaxis assay image analysis</h3>\n",
    "\n",
    "This image-analysis pipeline was used to analyze the recorded videos from the chemotaxis assays. This script was developped within the framework of the following publication:\n",
    "\n",
    "<em>de Schaetzen & Fan et al. Random encounters and predator locomotion drive the predation of Listeria monocytogenes by Acanthamoeba castellanii.</em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Importing the required libraries and tools</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, unicode_literals, print_function  #for compatibility with Python 2 and 3\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import trackpy as tp\n",
    "import trackpy.predict\n",
    "from tifffile import imsave, imread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Creating a folder structure for file saving</h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_path = r'F:\\Chemotaxis assay analysis\\PAS_Rep3_13012021'#Set the default folder, the folder mentioned here only serves as an example\n",
    "#the following definition allows for easy folder creation:\n",
    "def createFolder(directory):    \n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "## TIFF, in this folder the converted video files will be saved (the conversion happens in ImageJ/Fiji)\n",
    "TIFF_path = def_path + \"\\TIFF\"\n",
    "createFolder(TIFF_path)\n",
    "## TIFFcor, in this folder the median background corrected and guassian blurred video files will be saved\n",
    "TIFFcor_path = def_path + \"\\TIFFcor\"\n",
    "createFolder(TIFFcor_path)\n",
    "## MED, in this folder the median background file will be saved\n",
    "MED_path = def_path + \"\\MED\"\n",
    "createFolder(MED_path)\n",
    "## TIFFthres, in this folder the thresholded video files will be saved\n",
    "TIFFthres_path = def_path + \"\\TIFFthres\"\n",
    "createFolder(TIFFthres_path)\n",
    "## DATA_FEAT: folder in which feature CSV files will be saved \n",
    "DAFE_path = def_path + \"\\DATA_FEAT\"\n",
    "createFolder(DAFE_path)\n",
    "# DATA_TRAJ: folder in which trajectory CSV files will be saved  \n",
    "DATR_path = def_path + \"\\DATA_TRAJ\"\n",
    "createFolder(DATR_path)  \n",
    "## DATA_TRAJfilter: folder in which filtered trajectory CSV files will be saved  \n",
    "DATR_f_path = def_path + \"\\DATA_TRAJ_filter\"\n",
    "createFolder(DATR_f_path)    \n",
    "## DATA_TRAJ_MSD: location in which mean-squared-displacement CSV files will be saved  \n",
    "DATR_MSD_path = def_path + \"\\DATA_TRAJ_MSD\"\n",
    "createFolder(DATR_MSD_path)   \n",
    "## DATR_MSD_KT: location in which MSD files including translational component are saved\n",
    "DATR_MSD_TC_path = def_path + \"\\DATA_TRAJ_MSD_TC\"\n",
    "createFolder(DATR_MSD_TC_path) \n",
    "## DATA_TRAJ_MSD_filter: location in which the MSD filtered trajectory CSV files will be saved  \n",
    "DATR_MSD_f_path = def_path + \"\\DATA_TRAJ_MSD_filter\"\n",
    "createFolder(DATR_MSD_f_path)\n",
    "## DATA_TRAJ_meanpos: location in which mean position trajectory CSV files will be saved  \n",
    "DATR_meanpos_path = def_path + \"\\DATA_TRAJ_meanpos\"\n",
    "createFolder(DATR_meanpos_path)      \n",
    "## DATA_BINS_prob : location in which bin analyzed CSV files will be saved\n",
    "BINS_prob_path = def_path + \"\\DATA_BINS_prob\"\n",
    "createFolder(BINS_prob_path) \n",
    "## FIG_TRAJ: location in which trajectory plots will be saved  \n",
    "FIGtraj_path = def_path + \"\\FIG_TRAJ\"\n",
    "createFolder(FIGtraj_path) \n",
    "## FIG_MSD_traj: location in which msd filtered trajectory plots will be saved  \n",
    "FIG_MSD_traj_path = def_path + \"\\FIG_TRAJ_MSD_filter\"\n",
    "createFolder(FIG_MSD_traj_path)\n",
    "## FIGmsd_path: location in which the MSD plots will be saved\n",
    "FIGmsd_path = def_path + \"\\FIG_MSD\"\n",
    "createFolder(FIGmsd_path)   \n",
    "## FIG_TC: location in which the translational component histograms will be saved  \n",
    "FIGtc_path = def_path + \"\\FIG_TC\"\n",
    "createFolder(FIGtc_path)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Slicing the recorded video to the required ROI</h4>\n",
    "\n",
    "This step requires you to find the exact pixel-coordinates and width/height using the rectangle selection tool. The values for these parameters can be found in the bottom part of the ImageJ/Fiji menu-bar. Furthermore, it is assumed that the video-files have been converted from 16-bit .ND2 to 16-bit .TIFF. This can be done using the batch convert tool within ImageJ/Fiji (Process > Batch > Convert). Make sure to place the converted files into the TIFF folder.\n",
    "\n",
    "- RAW video files were named with their timestap, but always with 2 digits (e.g. for the recording in minute 1 the file would have had the name 01.nd2). This naming protocol is used throughout the script to assign timelabels in different resulting tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(TIFF_path) # set the working directory to the TIFF folder\n",
    "fl_TIFF = os.listdir(TIFF_path) # make a list of all filenames\n",
    "i = 1; # step variable\n",
    "js = 234 #Starting row for slice in pixels, in imageJ the y coordinate\n",
    "ks = 300 #Starting collumn for slice in pixels\n",
    "wh = 1491 #width and height of the area to be sliced in pixels\n",
    "for Value in fl_TIFF: # for loop that will cycle through each video-file\n",
    "    frames = np.array(imread(Value)) #import the video-file as a numpy array\n",
    "    frames_slice = frames[:,js:js+wh,ks:ks+wh] #slice the file to the specified coordinates\n",
    "    filename_slice = Value.replace('.tif','_SLICE.tif') #create a new filename\n",
    "    imsave(filename_slice, frames_slice) #save the sliced file \n",
    "    os.remove(Value) #remove the old non-sliced file \n",
    "    print(i, 'out of', len(fl_TIFF), ' files have been sliced')\n",
    "    i += 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Median background substraction and Gaussian blur</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(TIFF_path) # set the working directory to the TIFF folder \n",
    "fl_TIFF = os.listdir(TIFF_path) # make a list of all filenames\n",
    "i = 1 # step variable\n",
    "R_mid = 125 # the center 8-bit value around which all pixel values will be centered\n",
    "R_min = 0 # the minimum value of an 8-bit range\n",
    "R_max = 255 # the maximum value of an 8-bit range\n",
    "for Value in fl_TIFF: # for loop that will cycle through each video-file\n",
    "    os.chdir(TIFF_path) # set the working directory to the TIFF folder \n",
    "    frames = np.array(imread(Value)) # import the video-file as a numpy array\n",
    "    med_frames = np.median(frames, axis=0) # calculate the median value for each pixel over all frames\n",
    "    os.chdir(MED_path) # set the working directory to the MED folder \n",
    "    filename_med = Value.replace('.tif', '_MED.tif') # create a new filename\n",
    "    imsave(filename_med, med_frames) # save median pixel values\n",
    "    cor_frames = np.array((frames - med_frames) + R_mid, dtype = np.int32) # 1. substract the median pixel values for each respective pixel in each frame, this centers all pixel values around 0 - 2. add the R_zero value\n",
    "    cor_frames = np.where(cor_frames < R_min, R_min, cor_frames) # all pixel values lower than R_min will be set to R_min\n",
    "    cor_frames = np.where(cor_frames > R_max, R_max, cor_frames) # all pixel values higher than R_max will be set to R_max\n",
    "    cor_frames = np.uint8(cor_frames) # convert the corrected frames from 32-bit to 8 bit\n",
    "    gblur_frames = gaussian_filter(cor_frames, sigma = (0,2,2)) # Gaussian blur with a 2x2 kernel\n",
    "    os.chdir(TIFFcor_path) # set the working directory to the TIFFcor folder \n",
    "    filename_cor = Value.replace('.tif', '_COR_SCALE_GBLUR.tif') # create a new filename\n",
    "    imsave(filename_cor, gblur_frames) # save the median background corrected and Gaussian blurred frames\n",
    "    print(i, 'out of', len(fl_TIFF), ' .TIFF files have been median background corrected and rescaled')\n",
    "    i += 1;  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Thresholding</h4>\n",
    "\n",
    "This step requires you to find the thresholding value TV using ImageJ/Fiji (Image > Adjust > Threshold), for our experiments the TV-value was between 115-119. This has to be done for only one video-file for one experiment, assuming that no experimental setup changes where made during the microscopic image acquisition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(TIFFcor_path) # set the working directory to the TIFFcor folder\n",
    "fl_TIFF = os.listdir(TIFFcor_path) # make a list of all filenames\n",
    "TV = 116 # This value was determined using the threshold function in ImageJ, this value should be between 115-119\n",
    "i = 1;\n",
    "for Value in fl_TIFF: # for loop that will cycle through each video-file\n",
    "    os.chdir(TIFFcor_path) # set the working directory to the TIFFcor folder\n",
    "    frames = np.array(imread(Value)) # import the video-file as a numpy array\n",
    "    thres_frames = np.where(frames <= TV, frames, 255) # replace all pixel values higher than the TV-value with 255\n",
    "    filename_thres = Value.replace('.tif', '_THRES.tif') # create a new filename\n",
    "    os.chdir(TIFFthres_path) # set the working directory to the TIFFthres folder\n",
    "    imsave(filename_thres, thres_frames) # save the thresholded frames\n",
    "    print(i, 'out of', len(fl_TIFF), ' files have been gaussian blurred and thresholded')\n",
    "    i += 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Particle recognition and trajectory formation</h4>\n",
    "\n",
    "For more information regarding the TrackPy, we refer to the in-depth information provided by the TrackPy team on their github: http://soft-matter.github.io/trackpy/v0.5.0/. Furthermore, prior to the next analyses steps, the TrackPy parameters should be determined using the ACLI_TrackPy_parameterization script which can be found in the following github repository: https://github.com/Renderfarm/Acanthamoeba-Listeria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(TIFFthres_path) # set the working directory to the TIFFthres folder\n",
    "fl_THRES = os.listdir(TIFFthres_path) # make a list of all filenames\n",
    "i = 1; # step variable\n",
    "Dia = 9 # diameter: approximate diameter (in pixels) of the particles to be located\n",
    "MinMass = 0 # Minimum mass: the minimum integrated brightness/darkness (filter to remove spurious objects)\n",
    "Nsize = 1 # Noise size: width of the gaussian blur filter to remove noise\n",
    "sep = 5 # minumum separation (in pixels) between two features\n",
    "Pmem = 15 # Particle memory: the maximum number of frames during which a feature can vanish, then reappear nearby, and be considered the same particle.\n",
    "TrackTresh = 5 # Minimum number of points (video frames) to survive\n",
    "MaxT = 5 # Maximum amount of pixels a bacteria can move in between two consecutive frames\n",
    "for Value in fl_THRES: # for loop that will cycle through each video-file\n",
    "    os.chdir(TIFFthres_path) # set the working directory to the TIFFthres folder\n",
    "    frames = np.array(imread(Value) # import the frames as a numpy array\n",
    "    ## Batch locate particles in each frame of the stack with tp.batch(array, diameter, invert = True, noise_size, minmass, separation)\n",
    "    fe = tp.batch(frames, diameter = Dia, invert = True, noise_size = Nsize, minmass = MinMass, separation = sep);\n",
    "    os.chdir(DAFE_path) # set the working directory to the DAFE folder\n",
    "    filename_fe = Value.replace('.tif', '_feat.csv') # create a new filename\n",
    "    pd.DataFrame(fe).to_csv(filename_fe) # save the feature dataframe to a .csv file\n",
    "    ## predictive trajectory linking\n",
    "    pred = trackpy.predict.NearestVelocityPredict() #activate the predictive tracking feature of TrackPy\n",
    "    tr = pred.link_df(fe, search_range = MaxT, memory = Pmem) # create trajectories with the predictive tracking feature \n",
    "    os.chdir(DATR_path) # set the working directory to the DATR folder\n",
    "    filename_tr = Value.replace('.tif', '_traj.csv') # create a new filename\n",
    "    pd.DataFrame(tr).to_csv(filename_tr)# save the trajectory dataframe to a .csv file\n",
    "    ## Filter trajectories based on their occurance in consecutive frames\n",
    "    trf = tp.filter_stubs(tr, TrackTresh) # filter out trajectoreies based on TrackTresh\n",
    "    filename_trf = Value.replace('.tif', '_trajfilter.csv') # create a new filename\n",
    "    os.chdir(DATR_f_path)# set the working directory to the DATR_f folder\n",
    "    pd.DataFrame(trf).to_csv(filename_trf) # save the filtered trajectory dataframe to a .csv file\n",
    "    ## Plot of trajectories colored by particle\n",
    "    plt.figure(figsize = (5,5)) # create an empty plot\n",
    "    ax1 = plt.subplot(1,1,1) # add axes to the plot\n",
    "    tp.plot_traj(trf, ax=ax1,colorby = 'particle') # plot the trajectories\n",
    "    plotname_trf = Value.replace('.tif', '_traj.tif') # create a new plotname\n",
    "    os.chdir(FIGtraj_path) # set the working directory to the FIGtraj_path folder\n",
    "    plt.savefig(plotname_trf, format = 'tif', dpi = 300)  # save the plots as a tif file\n",
    "    print(i, 'out of', len(fl_TIFF), ' files have been analyzed ofr trajectories')\n",
    "    i += 1;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Mean squared displacement (MSD) + translational component calculations</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DATR_f_path) # set the working directory to the DATR_f folder\n",
    "fl_DATA = os.listdir(DATR_f_path) # create a list of all filenames\n",
    "# input parameters for MSD calculations\n",
    "x_lim = 1491 # width of the images in pixel value, determined in the slicing step\n",
    "w_ch = 1000 # width of the channel in micrometers\n",
    "fr_ps = 25 # fps of recorded videos\n",
    "l_t = 25 # maximum lag time\n",
    "tot_fr = 125 # total amount of frames in videos\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATA: # for loop that will cycle through each .csv-file\n",
    "    ## calculate the MSD's for each trajectory\n",
    "    os.chdir(DATR_f_path) # set the working directory to the DATR_f folder\n",
    "    trf = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    msd = tp.imsd(trf, w_ch/x_lim, fps = fr_ps, max_lagtime = l_t) # calculate the MSD of each trajectory\n",
    "    os.chdir(DATR_MSD_path) # set the working directory to the DATR_MSD folder\n",
    "    filename_msd = Value.replace('.csv', '_msd.csv') # create a new filename\n",
    "    pd.DataFrame(msd).to_csv(filename_msd) # save the MSD DataFrame as a .csv file\n",
    "    ## plot figure off all MSD's\n",
    "    plt.figure(figsize = (5,5)) # create an empty plot\n",
    "    ax_msd = plt.subplot(1,1,1) # add axes to the plot\n",
    "    ax_msd.plot(msd.index, msd, 'k-', alpha=0.1) # plot the MSD's\n",
    "    ax_msd.set(ylabel=r'$\\langle \\Delta r^2 \\rangle$ [$\\mu$m$^2$]', xlabel='lag time $t$') # label the axes\n",
    "    ax_msd.set_xscale('log') # rescale the x-axis to logarithmic\n",
    "    ax_msd.set_yscale('log') # rescale the y-axis to logarithmic\n",
    "    plotname_msd = Value.replace('.csv', '_MSD.tif') # create a new plotname\n",
    "    os.chdir(FIGmsd_path) # set the working directory to the FIGmsd folder\n",
    "    plt.savefig(plotname_msd, format = 'tif', dpi = 600) # save the MSD plot \n",
    "    ## calculate the translational component for filtering purposes\n",
    "    msdt = msd.transpose() # transposed the DataFrame to calculate the translational component\n",
    "    msdt.drop(msdt.loc[msdt[1.0] == 0].index, inplace=True)\n",
    "    msdt['tc'] = ((np.log10(msdt[l_t/fr_ps]) - np.log10(msdt[1/fr_ps]))/(np.log10(l_t/fr_ps)-np.log10(1/fr_ps))) # calculate the translational component based on the MSD curves\n",
    "    msdt = msdt.dropna() # drops rows from the dataframe that have no values\n",
    "    os.chdir(DATR_MSD_TC_path) # set the working directory to the DATR_MSD_TC folder\n",
    "    filename_tc = Value.replace('.csv', '_tc.csv') # create a new filename\n",
    "    pd.DataFrame(msdt).to_csv(filename_tc) # save the msdt DataFrame including tc data as a .csv file\n",
    "    ## plot a histogram of translational component\n",
    "    plt.figure(figsize = (5,5)) # create an empty plot\n",
    "    ax_tc = plt.subplot(1,1,1) # add axes to the plot\n",
    "    ax_tc.set_xlim([0,2]) # set the x-axis limit\n",
    "    plt.xticks(np.arange(0, 2.2, 0.2)) # set the x-axis ticks\n",
    "    plt.hist(msdt['tc'], bins = np.arange(0,2.1, 0.1)) # plot a histogram of tc data\n",
    "    plotname = Value.replace('.csv', '_tc.tif') # create a new plotname\n",
    "    os.chdir(FIGtc_path) # set the working directory to the FIG_TC folder\n",
    "    plt.savefig(plotname, format = 'tif', dpi = 600) # save the tc plot \n",
    "    print(i, 'out of', len(fl_DATA), ' files have been analyzed for msd and tc')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Filter out trajectories that are subdiffusive based on their translational component</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DATR_MSD_TC_path) # set the working directory to the DATR_MSD_KT folder\n",
    "fl_DATR_MSD_tc = os.listdir(DATR_MSD_TC_path) # create a list of filenames\n",
    "co_tc = 1.2 # cutoff value for tc\n",
    "x_lim = 1491 # width of the image in pixels\n",
    "y_lim = 1491 # height of the image in pixels\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_MSD_tc:  # for loop that will cycle through each csv-file\n",
    "    ## create a list of particles with their unique ID that have a translational component larger or equal than 1.2\n",
    "    os.chdir(DATR_MSD_TC_path) # set the working directory to the DATR_MSD_KT folder\n",
    "    msdt_tc = pd.read_csv(Value, index_col = 0) # import the .csv file as a DataFrame\n",
    "    msdt_tc = msdt_tc.loc[msdt_tc['tc'] >= co_tc] # filter out particles that are not-motile/subdiffusive\n",
    "    dpart =  list(msdt_tc.index.values) # make a list of all particles that are considered to be motile\n",
    "    filename_fe = Value.replace('_tc.csv', '.csv') # create a filename to call on a previously made trajectory .csv file\n",
    "    os.chdir(DATR_f_path) # set the working directory to the DATR_f folder\n",
    "    trf = pd.read_csv(filename_fe) # import the .csv file as a DataFrame\n",
    "    ## filter out all bacteria that did not meet the cut-off value\n",
    "    trf = trf.loc[trf['particle'].isin(dpart)] #filter out particles that have a tc value lower or equal than 1.2\n",
    "    os.chdir(DATR_MSD_f_path) # set the working directory to the DATR_MSD_f folder\n",
    "    filename_trf = filename_fe.replace('.csv', '_MSDfilter.csv') # create a new filename\n",
    "    pd.DataFrame(trf).to_csv(filename_trf) # save the filtered trajectory Dataframe to a .csv file\n",
    "    ## plot the filtered trajectories\n",
    "    plt.figure(figsize = (5,5)) # create an empty plot\n",
    "    ax1 = plt.subplot(1,1,1) # add axes to the plot\n",
    "    ax1.set_xlim([0,x_lim]) # set the x-axis limit\n",
    "    ax1.set_ylim([y_lim,0]) # set the y-axis limit\n",
    "    tp.plot_traj(trf, ax=ax1,colorby = 'particle') # plot the trajectories\n",
    "    plotname = Value.replace('.csv', '_MSD_traj.tif') # create a new plotname\n",
    "    os.chdir(FIG_MSD_traj_path) # set the working directory to the FIG_MSD_traj folder\n",
    "    plt.savefig(plotname, format = 'tif', dpi = 600) # save the plot as a .tif file\n",
    "    print(i, 'out of', len(fl_DATR_MSD_tc), ' files have been msd filtered for non-motile bacteria')\n",
    "    i += 1    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculate the mean position for each bacteria per timepoint </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(DATR_MSD_f_path) # set the working directory to the DATR_MSD_f folder\n",
    "fl_DATR_MSD_f = os.listdir(DATR_MSD_f_path) # create a list of all filenames\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_MSD_f: # for loop that will cycle through each .csv-file\n",
    "    os.chdir(DATR_MSD_f_path) # set the working directory to the DATR_MSD_f folder\n",
    "    trf = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    part = pd.DataFrame(trf.particle.unique(), columns = ['pID']) # create a Dataframe with a list of unique particle ID's\n",
    "    mp = pd.DataFrame() # create an empty DataFrame\n",
    "    for pID in part['pID']: # for loop that will cycle through each particle ID\n",
    "        pos = trf[trf.particle == pID] # for a given particle ID collect all positions\n",
    "        mx = pos['x'].mean() # calculate the mean x coordinate over all frames\n",
    "        my = pos['y'].mean() # calculate the mean y coordinate over all frames\n",
    "        stdevx = np.std(pos['x']) # calculate the stdev of x coordinates\n",
    "        stdevy = np.std(pos['y']) # calculate the stdev of y coordinates\n",
    "        tframes = (pos.frame.max() + 1) - (pos.frame.min() + 1) # calculate the amount of frames a particle was tracked (the +1 modifier is to account for the starting frame label of 0) \n",
    "        data = [(pID, mx, my, stdevx, stdevy, tframes)] # combine all previously calculated variables in a list\n",
    "        mps = pd.DataFrame(data, columns = ['pID','mx','my','stdevx','stdevy','tframes']) # add all calculated data to a DataFrame\n",
    "        mp = mp.append(mps, sort = False) # merge DataFrames into one \n",
    "    filename_mp = Value.replace('.csv', '_mp.csv') # create a new filename\n",
    "    os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder \n",
    "    pd.DataFrame(mp).to_csv(filename_mp) # save the mean position DataFrame to a .csv file\n",
    "    print(i, 'out of', len(fl_DATR_MSD_f), ' files have been analyzed for the bacterial mean position')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculate the relative cell concentrations over a number of bins for a chemotactic reponse from RIGHT to LEFT </h4>\n",
    "\n",
    "Use this script-block only when the chemical attractant is generated from the LEFT!\n",
    "Other versions of this script for chemical attractants generated from another direction can be found below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 5 # amount of bins\n",
    "x_lim = 1500 # width of the image in pixels\n",
    "w_ch = 1000 # width of the channel in microns\n",
    "x_step = x_lim/bins # width of each bin in pixels\n",
    "mpp = w_ch/x_lim # micron per pixel, conversion factor\n",
    "os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "fl_DATR_meanpos = os.listdir(DATR_meanpos_path) # create a list of all filenames\n",
    "rel_conc = pd.DataFrame() # create an empty DataFrame\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_meanpos: # for loop that will cycle through meanposition csv-file\n",
    "    os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "    mp = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    b = 1 # step variable for bins\n",
    "    x0 = 0 # starting coordinate\n",
    "    bin_cc = x_step/2 # central coordinate in pixels of each bin for plotting purposes\n",
    "    dbin = pd.DataFrame(columns=['x', 'count']) # create an empty DataFrame \n",
    "    while b <= bins: # a while function that will cycle through each bin\n",
    "        mp_bin = mp[(mp.mx >= x0) & (mp.mx <= (x0 + x_step))] # Select all mean positions that are situated within the borders of that given bin\n",
    "        counts = np.array(mp_bin['pID'].nunique()) # count the amount of unique particel ID's\n",
    "        bin_count = [(bin_cc, counts)] # create a list of the counts and central bin coordinate\n",
    "        dbin_row = pd.DataFrame(bin_count, columns=['x', 'count']) # make a Dataframe row of the \n",
    "        dbin = dbin.append(dbin_row, sort = False) # append the row to the bin data\n",
    "        x0 += x_step # increase the starting coordinate with the binwidth\n",
    "        bin_cc += x_step # increase the central bin coordinate with the binwidth\n",
    "        b += 1 # increase the bin step variable\n",
    "    dbin['rel_conc'] = dbin['count']/dbin['count'].sum() # calculate the relative concentration for each bin\n",
    "    dbin['x_um'] = dbin['x']*mpp # calculate the central coordinate of each bin in micrometers\n",
    "    os.chdir(BINS_prob_path)# set the working directory to the BINS_prob_path\n",
    "    filename_prob = Value.replace('.csv', '_bins.csv') # create a new filename\n",
    "    pd.DataFrame(dbin).to_csv(filename_prob) # save the the relative concentrations per bin for each individual timepoint in a .csv file\n",
    "    values = [(os.path.splitext(Value[0:2])[0], dbin.iloc[0]['rel_conc'], dbin.iloc[1]['rel_conc'], dbin.iloc[2]['rel_conc'], dbin.iloc[3]['rel_conc'], dbin.iloc[4]['rel_conc'])] # take the relative concentrations from each bin\n",
    "    rel_conc_row = pd.DataFrame(values, columns = ['time', 'R1', 'R2', 'R3', 'R4', 'R5']) # put all values in a DataFrame row\n",
    "    rel_conc = rel_conc.append(rel_conc_row, sort = False) # combine all rows into one DataFrame\n",
    "    print(i, 'out of', len(fl_DATR_meanpos), ' files have been analyzed for their relative concentrations in each bin')\n",
    "    i += 1   \n",
    "os.chdir(def_path) # set the working directory to the default folder location\n",
    "pd.DataFrame(rel_conc).to_csv('Relative_concentration_bins.csv') # save the the relative concentrations per bin for all timepoints in a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculate the relative cell concentrations over a number of bins for a chemotactic reponse from LEFT to RIGHT </h4>\n",
    "\n",
    "Use this script-block only when the chemical attractant is generated from the RIGHT!\n",
    "The only difference between this block and the previous is the order in which the relative concentrations are collected and saved into the Relative_concentration_bins.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 5 # amount of bins\n",
    "x_lim = 1975 # width of the image in pixels\n",
    "w_ch = 1000 # width of the channel in microns\n",
    "x_step = x_lim/bins # width of each bin in pixels\n",
    "mpp = w_ch/x_lim # micron per pixel, conversion factor\n",
    "os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "fl_DATR_meanpos = os.listdir(DATR_meanpos_path) # create a list of all filenames\n",
    "rel_conc = pd.DataFrame() # create an empty DataFrame\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_meanpos: # for loop that will cycle through meanposition csv-file\n",
    "    os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "    mp = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    b = 1 # step variable for bins\n",
    "    x0 = 0 # starting coordinate\n",
    "    bin_cc = x_step/2 # central coordinate in pixels of each bin for plotting purposes\n",
    "    dbin = pd.DataFrame(columns=['x', 'count']) # create an empty DataFrame \n",
    "    while b <= bins: # a while function that will cycle through each bin\n",
    "        mp_bin = mp[(mp.mx >= x0) & (mp.mx <= (x0 + x_step))] # Select all mean positions that are situated within the borders of that given bin\n",
    "        counts = np.array(mp_bin['pID'].nunique()) # count the amount of unique particel ID's\n",
    "        bin_count = [(bin_cc, counts)] # create a list of the counts and central bin coordinate\n",
    "        dbin_row = pd.DataFrame(bin_count, columns=['x', 'count']) # make a Dataframe row of the \n",
    "        dbin = dbin.append(dbin_row, sort = False) # append the row to the bin data\n",
    "        x0 += x_step # increase the starting coordinate with the binwidth\n",
    "        bin_cc += x_step # increase the central bin coordinate with the binwidth\n",
    "        b += 1 # increase the bin step variable\n",
    "    dbin['rel_conc'] = dbin['count']/dbin['count'].sum() # calculate the relative concentration for each bin\n",
    "    dbin['x_um'] = dbin['x']*mpp # calculate the central coordinate of each bin in micrometers\n",
    "    os.chdir(BINS_prob_path)# set the working directory to the BINS_prob_path\n",
    "    filename_prob = Value.replace('.csv', '_bins.csv') # create a new filename\n",
    "    pd.DataFrame(dbin).to_csv(filename_prob) # save the the realtiove concentrations per bin for each timepoint in a .csv file\n",
    "    values = [(os.path.splitext(Value[0:2])[0], dbin.iloc[4]['rel_conc'], dbin.iloc[3]['rel_conc'], dbin.iloc[2]['rel_conc'], dbin.iloc[1]['rel_conc'], dbin.iloc[0]['rel_conc'])] # take the relative concentrations from each bin\n",
    "    rel_conc_row = pd.DataFrame(values, columns = ['time', 'R1', 'R2', 'R3', 'R4', 'R5']) # put all values in a DataFrame row\n",
    "    rel_conc = rel_conc.append(rel_conc_row, sort = False) # combine all rows into one DataFrame\n",
    "    print(i, 'out of', len(fl_DATR_meanpos), ' files have been analyzed for their relative concentrations in each bin')\n",
    "    i += 1   \n",
    "os.chdir(def_path) # set the working directory to the default folder location\n",
    "pd.DataFrame(rel_conc).to_csv('Relative_concentration_bins.csv') # save the the relative concentrations per bin for all timepoints in a .csv file    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculate the relative cell concentrations over a number of bins for a chemotactic reponse from TOP to BOTTOM </h4>\n",
    "\n",
    "Use this script-block only when the chemical attractant is generated from the BOTTOM!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 5 # amount of bins\n",
    "y_lim = 1491 # width of the image in pixels\n",
    "w_ch = 1000 # width of the channel in microns\n",
    "y_step = y_lim/bins # width of each bin in pixels\n",
    "mpp = w_ch/y_lim # micron per pixel, conversion factor\n",
    "os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "fl_DATR_meanpos = os.listdir(DATR_meanpos_path) # create a list of all filenames\n",
    "rel_conc = pd.DataFrame() # create an empty DataFrame\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_meanpos: # for loop that will cycle through meanposition csv-file\n",
    "    os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "    mp = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    b = 1 # step variable for bins\n",
    "    y0 = 0 # starting coordinate\n",
    "    bin_cc = y_step/2 # central coordinate in pixels of each bin for plotting purposes\n",
    "    dbin = pd.DataFrame(columns=['y', 'count']) # create an empty DataFrame \n",
    "    while b <= bins: # a while function that will cycle through each bin\n",
    "        mp_bin = mp[(mp.my >= y0) & (mp.my <= (y0 + y_step))] # Select all mean positions that are situated within the borders of that given bin\n",
    "        counts = np.array(mp_bin['pID'].nunique()) # count the amount of unique particel ID's\n",
    "        bin_count = [(bin_cc, counts)] # create a list of the counts and central bin coordinate\n",
    "        dbin_row = pd.DataFrame(bin_count, columns=['y', 'count']) # make a Dataframe row of the \n",
    "        dbin = dbin.append(dbin_row, sort = False) # append the row to the bin data\n",
    "        y0 += y_step # increase the starting coordinate with the binwidth\n",
    "        bin_cc += y_step # increase the central bin coordinate with the binwidth\n",
    "        b += 1 # increase the bin step variable\n",
    "    dbin['rel_conc'] = dbin['count']/dbin['count'].sum() # calculate the relative concentration for each bin\n",
    "    dbin['y_um'] = dbin['y']*mpp # calculate the central coordinate of each bin in micrometers\n",
    "    os.chdir(BINS_prob_path)# set the working directory to the BINS_prob_path\n",
    "    filename_prob = Value.replace('.csv', '_bins.csv') # create a new filename\n",
    "    pd.DataFrame(dbin).to_csv(filename_prob) # save the the realtiove concentrations per bin for each timepoint in a .csv file\n",
    "    values = [(os.path.splitext(Value[0:2])[0], dbin.iloc[4]['rel_conc'], dbin.iloc[3]['rel_conc'], dbin.iloc[2]['rel_conc'], dbin.iloc[1]['rel_conc'], dbin.iloc[0]['rel_conc'])] # take the relative concentrations from each bin\n",
    "    rel_conc_row = pd.DataFrame(values, columns = ['time', 'R1', 'R2', 'R3', 'R4', 'R5']) # put all values in a DataFrame row\n",
    "    rel_conc = rel_conc.append(rel_conc_row, sort = False) # combine all rows into one DataFrame\n",
    "    print(i, 'out of', len(fl_DATR_meanpos), ' files have been analyzed for their relative concentrations in each bin')\n",
    "    i += 1   \n",
    "os.chdir(def_path) # set the working directory to the default folder location\n",
    "pd.DataFrame(rel_conc).to_csv('Relative_concentration_bins.csv') # save the the relative concentrations per bin for all timepoints in a .csv file    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Calculate the relative cell concentrations over a number of bins for a chemotactic reponse from BOTTOM to TOP </h4>\n",
    "\n",
    "Use this script-block only when the chemical attractant is generated from the TOP!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 5 # amount of bins\n",
    "y_lim = 1467 # width of the image in pixels\n",
    "w_ch = 1000 # width of the channel in microns\n",
    "y_step = y_lim/bins # width of each bin in pixels\n",
    "mpp = w_ch/y_lim # micron per pixel, conversion factor\n",
    "os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "fl_DATR_meanpos = os.listdir(DATR_meanpos_path) # create a list of all filenames\n",
    "rel_conc = pd.DataFrame() # create an empty DataFrame\n",
    "i = 1 # step variable\n",
    "for Value in fl_DATR_meanpos: # for loop that will cycle through meanposition csv-file\n",
    "    os.chdir(DATR_meanpos_path) # set the working directory to the DATR_meanpos folder\n",
    "    mp = pd.read_csv(Value) # import the .csv file as a DataFrame\n",
    "    b = 1 # step variable for bins\n",
    "    y0 = 0 # starting coordinate\n",
    "    bin_cc = y_step/2 # central coordinate in pixels of each bin for plotting purposes\n",
    "    dbin = pd.DataFrame(columns=['y', 'count']) # create an empty DataFrame \n",
    "    while b <= bins: # a while function that will cycle through each bin\n",
    "        mp_bin = mp[(mp.my >= y0) & (mp.my <= (y0 + y_step))] # Select all mean positions that are situated within the borders of that given bin\n",
    "        counts = np.array(mp_bin['pID'].nunique()) # count the amount of unique particel ID's\n",
    "        bin_count = [(bin_cc, counts)] # create a list of the counts and central bin coordinate\n",
    "        dbin_row = pd.DataFrame(bin_count, columns=['y', 'count']) # make a Dataframe row of the \n",
    "        dbin = dbin.append(dbin_row, sort = False) # append the row to the bin data\n",
    "        y0 += y_step # increase the starting coordinate with the binwidth\n",
    "        bin_cc += y_step # increase the central bin coordinate with the binwidth\n",
    "        b += 1 # increase the bin step variable\n",
    "    dbin['rel_conc'] = dbin['count']/dbin['count'].sum() # calculate the relative concentration for each bin\n",
    "    dbin['y_um'] = dbin['y']*mpp # calculate the central coordinate of each bin in micrometers\n",
    "    os.chdir(BINS_prob_path)# set the working directory to the BINS_prob_path\n",
    "    filename_prob = Value.replace('.csv', '_bins.csv') # create a new filename\n",
    "    pd.DataFrame(dbin).to_csv(filename_prob) # save the the realtiove concentrations per bin for each timepoint in a .csv file\n",
    "    values = [(os.path.splitext(Value[0:2])[0], dbin.iloc[0]['rel_conc'], dbin.iloc[1]['rel_conc'], dbin.iloc[2]['rel_conc'], dbin.iloc[3]['rel_conc'], dbin.iloc[4]['rel_conc'])] # take the relative concentrations from each bin\n",
    "    rel_conc_row = pd.DataFrame(values, columns = ['time', 'R1', 'R2', 'R3', 'R4', 'R5']) # put all values in a DataFrame row\n",
    "    rel_conc = rel_conc.append(rel_conc_row, sort = False) # combine all rows into one DataFrame\n",
    "    print(i, 'out of', len(fl_DATR_meanpos), ' files have been analyzed for their relative concentrations in each bin')\n",
    "    i += 1   \n",
    "os.chdir(def_path) # set the working directory to the default folder location\n",
    "pd.DataFrame(rel_conc).to_csv('Relative_concentration_bins.csv') # save the the relative concentrations per bin for all timepoints in a .csv file    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
